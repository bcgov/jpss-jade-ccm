= Kafka example : A Camel Quarkus example
:cq-example-description: An example that shows how to produce and consume messages in a Kafka topic, created on a Kafka cluster with OpenShift Streams for Apache Kafka.

{cq-description}

TIP: Check the https://camel.apache.org/camel-quarkus/latest/first-steps.html[Camel Quarkus User guide] for prerequisites
and other general information.

== Prerequisites

This quickstart assumes that you already have access to Red Hat OpenShift Streams for Apache Kafka[https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/getting-started].

== Provision a Kafka cluster with OpenShift Streams for Apache Kafka
You can provision either using the UI or RHOAS cli, as described in following sections

== Provision a Kafka cluster with Openshift Streams for Apache Kafka using UI
1. Go to https://cloud.redhat.com/application-services[cloud.redhat.com], and log with your Red Hat account, or create one.
2. Create a new Kafka instance, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a#_b4f95791-b992-429d-9e8e-cceb63ae829f[Creating a Kafka instance in OpenShift Streams for Apache Kafka Guide].
3. Create a topic named `test` following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a#_e7458089-1dfe-4d51-bfd0-990014e7226c[Creating a Kafka topic in OpenShift Streams for Apache Kafka Guide].
4. Create a set of credentials, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a#_7cb5e3f0-4b76-408d-b245-ff6959d3dbf7[Creating a service account to connect to a Kafka instance in OpenShift Streams for Apache Kafka Guide].
5. Set permissions for the service account, following the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f351c4bd-9840-42ef-bcf2-b0c9be4ee30a#_3dc6265b-96f9-49fd-b2f6-9e3688859539[Setting permissions for a service account in a Kafka instance in OpenShift Streams for Apache Kafka Guide].

IMPORTANT: The minimal service account permissions needed to run this tutorial are : setting the topic `test` access to `Allow All`, and setting the consumer Group `*` access to `Allow Read`

== Provision a Kafka cluster with Openshift Streams for Apache Kafka using RHOAS cli
1. Open the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/f520e427-cad2-40ce-823d-96234ccbc047[Installing and configuring the rhoas CLI documentation].
2. Install the RHOAS cli, following the `Installing the rhoas CLI` section.
3. Login to the Openshift Streams for Apache Kafka, following the `Logging in to rhoas` section.
4. Open the https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3#_fe8d86db-14f8-4adb-a05a-1c3736c6d8dc[Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka documentation].
5. Create a new Kafka instance, following the `Creating a Kafka instance` in the `Using rhoas` section.
6. Create a topic named `test`, following the `Creating a Kafka topic` in the `Using rhoas` section.
7. Create a set of credentials, and manage permissions following the `Creating a service account` in the `Using rhoas` section.

IMPORTANT: The minimal service account permissions needed to run this tutorial are : setting the topic `test` access to `Allow All`, and setting the consumer Group `*` access to `Allow Read`

== Set the right Kafka client credentials
In the Kafka Instances page of the web console, for the relevant Kafka instance that you want to connect to, select the options icon (three vertical dots) and click View connection information.

Copy the Bootstrap server and  the SASL/OAUTHBEARER Token endpoint URL, needed for the configuration.

---
If you want to connect to your Kafka instance using SASL Plain, you'd need to set system property `-Dquarkus.profile=sasl-plain` (so the correct `application-sasl-plain.properties` is used) and provide following properties:

- system property `kafka.brokers.url` (or env variable `KAFKA_BROKERS_URL`)
- system property `kafka.sasl.client.id` (or env variable `KAFKA_SASL_CLIENT_ID`)
- system property `kafka.sasl.client.secret` (or env variable `KAFKA_SASL_CLIENT_SECRET`)

---
If you want to connect to your Kafka instance using SASL Oauth Bearer, you'd need to set system property `-Dquarkus.profile=sasl-oauth` (so the correct `application-sasl-oauth.properties` is used) and provide following properties:

- system property `kafka.brokers.url` (or env variable `KAFKA_BROKERS_URL`)
- system property `kafka.sasl.client.id` (or env variable `KAFKA_SASL_CLIENT_ID`)
- system property `kafka.sasl.client.secret` (or env variable `KAFKA_SASL_CLIENT_SECRET`)
- system property `kafka.sasl.oauthbearer.token.url` (or env variable `KAFKA_SASL_OAUTHBEARER_TOKEN_URL`)

== Start in Development mode

Run the application in development mode.

[source,shell]
----
$ mvn clean compile quarkus:dev
----

The above command compiles the project, starts the application and lets the Quarkus tooling watch for changes in your
workspace. Any modifications in your project will automatically take effect in the running application.

TIP: Please refer to the Development mode section of
https://camel.apache.org/camel-quarkus/latest/first-steps.html#_development_mode[Camel Quarkus User guide] for more details.

You should start to see some log messages appearing on the console.

Every 10 seconds the timer component triggers the generation of random Message and send it to the Kafka topic `Test`.

[source,shell]
----
[FromTimer2Kafka] (Camel (camel-1) thread #2 - KafkaProducer[test]) Message sent correctly sent to the topic! : "Message #1"
----

Next a Kafka consumer reads the messages and put them in a seda queue.

[source,shell]
----
[FromKafka2Seda] (Camel (camel-1) thread #0 - KafkaConsumer[test]) Received : "Message #1"
----

Next pull a message from the queue :
[source,shell]
----
$ curl -X GET http://0.0.0.0:8080/example
----

=== Package and run the application

Once you are done with developing you may want to package and run the application.

==== JVM mode

[source,shell]
----
$ mvn clean package -DskipTests
$ java -jar target/quarkus-app/quarkus-run.jar
----

==== Native mode

IMPORTANT: Native mode requires having GraalVM and other tools installed. Please check the Prerequisites section
of https://camel.apache.org/camel-quarkus/latest/first-steps.html#_prerequisites[Camel Quarkus User guide].

To prepare a native executable using GraalVM, run the following command:

[source,shell]
----
$ mvn clean package -DskipTests -Pnative
$ ./target/*-runner
----

=== Deploying to OpenShift
Create a new project named `camel-kafka-ns`.

[source,shell]
----
$ oc new-project camel-kafka-ns
----

To deploy the application to OpenShift run the following command.

==== JVM mode

[source,shell]
----
$ mvn clean package -DskipTests -Dquarkus.kubernetes.deploy=true
----

==== Native mode

[source,shell]
----
$ mvn clean package -DskipTests -Dquarkus.kubernetes.deploy=true -Pnative
----

[NOTE]
====
If you need to configure container resource limits & requests, or enable the Quarkus Kubernetes client to trust self signed certificates, you can find these configuration options in `src/main/resources/application.properties`. Simply uncomment them and set your desired values.
====

Check the pod is running.

[source,shell]
----
$ oc get pods
NAME                                           READY   STATUS    RESTARTS   AGE
camel-quarkus-examples-kafka-dbc56974b-ph29m   1/1     Running   0          2m34s
----

Tail the application logs.

[source,shell]
----
$ oc logs -f camel-quarkus-examples-kafka-dbc56974b-ph29m
----

Get the service route.
[source,shell]
----
$ oc get route camel-quarkus-examples-kafka
----

Next use the route, to pull a message from the queue :
[source,shell]
----
$ curl -X GET <YOUR_ROUTE>/example
----

To clean up do.

[source,shell]
----
$ oc delete all -l app.kubernetes.io/name=camel-quarkus-examples-kafka
$ oc delete project camel-kafka-ns
----

For more information about deploying Quarkus applications to OpenShift, refer to the https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/1.11/html/deploying_your_quarkus_applications_to_openshift/ref-openshift-build-strategies-and-quarkus_quarkus-openshift[documentation].
